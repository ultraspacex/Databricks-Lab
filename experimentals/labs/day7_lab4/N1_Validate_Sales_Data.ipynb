{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88cb6b11-d043-493d-8634-55c1fcb91369",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, to_date\n",
    "from pyspark.sql.types import IntegerType, DateType, DoubleType, StringType\n",
    "\n",
    "dbutils.widgets.text(\"sales_table_name\", \"bronze_sales\")\n",
    "dbutils.widgets.text(\"database_name\", \"module2_db\")\n",
    "dbutils.widgets.dropdown(\"force_valid_status_for_testing\", \"False\", [\"True\", \"False\"])\n",
    "\n",
    "sales_table = dbutils.widgets.get(\"sales_table_name\")\n",
    "db_name = dbutils.widgets.get(\"database_name\")\n",
    "force_valid_status = dbutils.widgets.get(\"force_valid_status_for_testing\") == \"True\"\n",
    "full_sales_table_name = f\"{db_name}.{sales_table}\"\n",
    "\n",
    "try:\n",
    "    df_sales_raw = spark.table(full_sales_table_name)\n",
    "except Exception as e:\n",
    "    dbutils.jobs.taskValues.set(key=\"validation_status\", value=\"ERROR_READING_TABLE\")\n",
    "    dbutils.jobs.taskValues.set(key=\"validation_error_message\", value=str(e))\n",
    "    dbutils.notebook.exit(f\"Failed to read table: {full_sales_table_name}\")\n",
    "\n",
    "# Cast columns to expected types\n",
    "df_sales = df_sales_raw\n",
    "df_sales = df_sales.withColumn(\"OrderDate_casted\", col(\"OrderDate\").cast(DateType()))\n",
    "df_sales = df_sales.withColumn(\"Quantity_casted\", col(\"Quantity\").cast(IntegerType()))\n",
    "df_sales = df_sales.withColumn(\"UnitPrice_casted\", col(\"UnitPrice\").cast(DoubleType()))\n",
    "\n",
    "# Check for missing required columns after casting\n",
    "required_cols = [\"SalesOrderNumber\", \"OrderDate_casted\", \"CustomerID\", \"Item\", \"Quantity_casted\", \"UnitPrice_casted\"]\n",
    "missing_cols_source = [c.replace(\"_casted\", \"\") for c in required_cols if c.replace(\"_casted\", \"\") not in df_sales_raw.columns]\n",
    "\n",
    "if missing_cols_source:\n",
    "    error_message = f\"Missing source columns: {', '.join(missing_cols_source)}\"\n",
    "    dbutils.jobs.taskValues.set(key=\"validation_status\", value=\"INVALID_SCHEMA\")\n",
    "    dbutils.jobs.taskValues.set(key=\"validation_error_message\", value=error_message)\n",
    "    dbutils.notebook.exit(error_message)\n",
    "\n",
    "# Perform data quality checks\n",
    "null_sales_order_number_count = df_sales.filter(col(\"SalesOrderNumber\").isNull()).count()\n",
    "null_order_date_count = df_sales.filter(col(\"OrderDate_casted\").isNull()).count()\n",
    "null_customer_id_count = df_sales.filter(col(\"CustomerID\").isNull()).count()\n",
    "null_item_count = df_sales.filter(col(\"Item\").isNull()).count()\n",
    "invalid_quantity_count = df_sales.filter(col(\"Quantity_casted\").isNull() | (col(\"Quantity_casted\") <= 0)).count()\n",
    "null_unit_price_count = df_sales.filter(col(\"UnitPrice_casted\").isNull() | (col(\"UnitPrice_casted\") < 0)).count()\n",
    "\n",
    "validation_status_actual = \"VALID\"\n",
    "error_message = \"\"\n",
    "if null_sales_order_number_count > 0: validation_status_actual = \"INVALID\"; error_message += f\"Null SalesOrderNumber. \"\n",
    "if null_order_date_count > 0: validation_status_actual = \"INVALID\"; error_message += f\"Null/invalid OrderDate. \"\n",
    "if null_customer_id_count > 0: validation_status_actual = \"INVALID\"; error_message += f\"Null CustomerID. \"\n",
    "if null_item_count > 0: validation_status_actual = \"INVALID\"; error_message += f\"Null Item. \"\n",
    "if invalid_quantity_count > 0: validation_status_actual = \"INVALID\"; error_message += f\"Null/non-positive Quantity. \"\n",
    "if null_unit_price_count > 0: validation_status_actual = \"INVALID\"; error_message += f\"Null/negative UnitPrice. \"\n",
    "\n",
    "final_validation_status = \"VALID\" if force_valid_status else validation_status_actual\n",
    "final_error_message = \"Forced VALID for testing\" if force_valid_status else error_message\n",
    "\n",
    "dbutils.jobs.taskValues.set(key=\"validation_status\", value=final_validation_status)\n",
    "dbutils.jobs.taskValues.set(key=\"source_table_record_count\", value=df_sales_raw.count())\n",
    "if final_validation_status == \"INVALID\":\n",
    "    dbutils.jobs.taskValues.set(key=\"validation_error_message\", value=final_error_message)\n",
    "dbutils.notebook.exit(final_validation_status)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "N1_Validate_Sales_Data",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
